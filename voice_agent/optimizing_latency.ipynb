{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d24368",
   "metadata": {},
   "source": [
    "## Optimization Guidelines\n",
    "\n",
    "### 1. LLM Optimization\n",
    "- Use appropriate temperature settings for your use case\n",
    "- Optimize max_tokens based on expected response length\n",
    "- Consider using smaller models for faster responses\n",
    "\n",
    "### 2. STT Optimization\n",
    "- Enable streaming for faster initial responses\n",
    "- Use appropriate sampling rates\n",
    "- Implement proper error handling\n",
    "\n",
    "### 3. TTS Optimization\n",
    "- Balance stability and similarity boost\n",
    "- Enable streaming for faster audio delivery\n",
    "- Cache frequently used responses\n",
    "\n",
    "### 4. General Tips\n",
    "- Monitor and log performance metrics\n",
    "- Implement proper error handling\n",
    "- Use appropriate model sizes for your use case\n",
    "- Consider latency vs quality tradeoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8041c",
   "metadata": {},
   "source": [
    "# Voice Agent Latency Optimization\n",
    "\n",
    "This notebook demonstrates advanced techniques for optimizing the latency and performance of voice-enabled AI agents. It provides comprehensive metrics collection and analysis for each component of the voice interaction pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Monitoring Overview\n",
    "\n",
    "The system tracks several key performance indicators:\n",
    "\n",
    "1. **LLM Performance**\n",
    "   - Token processing speed\n",
    "   - Time to First Token (TTFT)\n",
    "   - Total token usage\n",
    "\n",
    "2. **Speech-to-Text Performance**\n",
    "   - Processing duration\n",
    "   - Audio duration analysis\n",
    "   - Streaming efficiency\n",
    "\n",
    "3. **Text-to-Speech Performance**\n",
    "   - Time to First Byte (TTFB)\n",
    "   - Audio generation speed\n",
    "   - Stream processing metrics\n",
    "\n",
    "4. **End-of-Utterance Detection**\n",
    "   - Detection latency\n",
    "   - Transcription delay\n",
    "   - Overall response time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e909a34-31f1-4e90-a142-8870a6c24180",
   "metadata": {},
   "source": [
    "## Step 1: Import LiveKit Agent Modules and Plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512fe011-1747-495b-9351-286b4e2f5c53",
   "metadata": {
    "height": 319
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/User/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(override=True)\n",
    "\n",
    "logger = logging.getLogger(\"dlai-agent\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from livekit import agents\n",
    "from livekit.agents import Agent, AgentSession, JobContext, WorkerOptions, jupyter\n",
    "from livekit.plugins import (\n",
    "    openai,\n",
    "    elevenlabs,\n",
    "    silero,\n",
    ")\n",
    "\n",
    "from livekit.agents.metrics import LLMMetrics, STTMetrics, TTSMetrics, EOUMetrics\n",
    "import asyncio\n",
    "\n",
    "## System Configuration\n",
    "\n",
    "# Importing required modules for metrics collection and performance monitoring. This includes:\n",
    "# - LiveKit Agent core modules\n",
    "# - Performance metrics collectors\n",
    "# - Voice processing plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00efd4-d48d-4dac-b629-ab6a4c198b73",
   "metadata": {
    "height": 1084
   },
   "outputs": [],
   "source": [
    "class MetricsAgent(Agent):\n",
    "    def __init__(self) -> None:\n",
    "        llm = openai.LLM(model=\"gpt-4o\")\n",
    "        #llm = openai.LLM(model=\"gpt-4o-mini\")   # Example with lower latency\n",
    "        stt = openai.STT(model=\"whisper-1\")\n",
    "        tts = elevenlabs.TTS()\n",
    "        silero_vad = silero.VAD.load()\n",
    "        \n",
    "        super().__init__(\n",
    "            instructions=\"You are a helpful assistant communicating via voice\",\n",
    "            stt=stt,\n",
    "            llm=llm,\n",
    "            tts=tts,\n",
    "            vad=silero_vad,\n",
    "        )\n",
    "\n",
    "        def llm_metrics_wrapper(metrics: LLMMetrics):\n",
    "            asyncio.create_task(self.on_llm_metrics_collected(metrics))\n",
    "        llm.on(\"metrics_collected\", llm_metrics_wrapper)\n",
    "\n",
    "        def stt_metrics_wrapper(metrics: STTMetrics):\n",
    "            asyncio.create_task(self.on_stt_metrics_collected(metrics))\n",
    "        stt.on(\"metrics_collected\", stt_metrics_wrapper)\n",
    "\n",
    "        def eou_metrics_wrapper(metrics: EOUMetrics):\n",
    "            asyncio.create_task(self.on_eou_metrics_collected(metrics))\n",
    "        stt.on(\"eou_metrics_collected\", eou_metrics_wrapper)\n",
    "\n",
    "        def tts_metrics_wrapper(metrics: TTSMetrics):\n",
    "            asyncio.create_task(self.on_tts_metrics_collected(metrics))\n",
    "        tts.on(\"metrics_collected\", tts_metrics_wrapper)\n",
    "\n",
    "    async def on_llm_metrics_collected(self, metrics: LLMMetrics) -> None:\n",
    "        print(\"\\n--- LLM Metrics ---\")\n",
    "        print(f\"Prompt Tokens: {metrics.prompt_tokens}\")\n",
    "        print(f\"Completion Tokens: {metrics.completion_tokens}\")\n",
    "        print(f\"Tokens per second: {metrics.tokens_per_second:.4f}\")\n",
    "        print(f\"TTFT: {metrics.ttft:.4f}s\")\n",
    "        print(\"------------------\\n\")\n",
    "\n",
    "    async def on_stt_metrics_collected(self, metrics: STTMetrics) -> None:\n",
    "        print(\"\\n--- STT Metrics ---\")\n",
    "        print(f\"Duration: {metrics.duration:.4f}s\")\n",
    "        print(f\"Audio Duration: {metrics.audio_duration:.4f}s\")\n",
    "        print(f\"Streamed: {'Yes' if metrics.streamed else 'No'}\")\n",
    "        print(\"------------------\\n\")\n",
    "\n",
    "    async def on_eou_metrics_collected(self, metrics: EOUMetrics) -> None:\n",
    "        print(\"\\n--- End of Utterance Metrics ---\")\n",
    "        print(f\"End of Utterance Delay: {metrics.end_of_utterance_delay:.4f}s\")\n",
    "        print(f\"Transcription Delay: {metrics.transcription_delay:.4f}s\")\n",
    "        print(\"--------------------------------\\n\")\n",
    "\n",
    "    async def on_tts_metrics_collected(self, metrics: TTSMetrics) -> None:\n",
    "        print(\"\\n--- TTS Metrics ---\")\n",
    "        print(f\"TTFB: {metrics.ttfb:.4f}s\")\n",
    "        print(f\"Duration: {metrics.duration:.4f}s\")\n",
    "        print(f\"Audio Duration: {metrics.audio_duration:.4f}s\")\n",
    "        print(f\"Streamed: {'Yes' if metrics.streamed else 'No'}\")\n",
    "        print(\"------------------\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e827a-8e2e-4f1d-8f8c-9486828f951d",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "async def entrypoint(ctx: JobContext):\n",
    "    await ctx.connect()\n",
    "\n",
    "    session = AgentSession()\n",
    "\n",
    "    await session.start(\n",
    "        agent=MetricsAgent(),\n",
    "        room=ctx.room,\n",
    "    )\n",
    "\n",
    "class MetricsAgent(Agent):\n",
    "    \"\"\"Agent implementation with comprehensive performance monitoring.\n",
    "    \n",
    "    This agent extends the base voice agent with detailed metrics collection\n",
    "    and analysis capabilities for all components of the voice interaction pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        # Initialize core components with performance monitoring\n",
    "        llm = openai.LLM(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.7,  # Adjust for balance of creativity vs determinism\n",
    "            max_tokens=150    # Optimize for response length\n",
    "        )\n",
    "        stt = openai.STT(\n",
    "            model=\"whisper-1\",\n",
    "            response_format=\"verbose_json\"  # Enable detailed metrics\n",
    "        )\n",
    "        tts = elevenlabs.TTS(\n",
    "            stability=0.5,      # Balance between speed and quality\n",
    "            similarity_boost=0.5 # Optimize voice consistency\n",
    "        )\n",
    "        silero_vad = silero.VAD.load(\n",
    "            threshold=0.5,  # Adjust for optimal voice detection\n",
    "            sampling_rate=16000\n",
    "        )\n",
    "        \n",
    "        super().__init__(\n",
    "            instructions=\"You are a helpful assistant communicating via voice\",\n",
    "            stt=stt,\n",
    "            llm=llm,\n",
    "            tts=tts,\n",
    "            vad=silero_vad,\n",
    "        )\n",
    "\n",
    "        # Set up metrics collectors\n",
    "        self._setup_metrics_collectors(llm, stt, tts)\n",
    "\n",
    "    def _setup_metrics_collectors(self, llm, stt, tts):\n",
    "        \"\"\"Configure metrics collection for all components.\"\"\"\n",
    "        def llm_metrics_wrapper(metrics: LLMMetrics):\n",
    "            asyncio.create_task(self.on_llm_metrics_collected(metrics))\n",
    "        llm.on(\"metrics_collected\", llm_metrics_wrapper)\n",
    "\n",
    "        def stt_metrics_wrapper(metrics: STTMetrics):\n",
    "            asyncio.create_task(self.on_stt_metrics_collected(metrics))\n",
    "        stt.on(\"metrics_collected\", stt_metrics_wrapper)\n",
    "\n",
    "        def eou_metrics_wrapper(metrics: EOUMetrics):\n",
    "            asyncio.create_task(self.on_eou_metrics_collected(metrics))\n",
    "        stt.on(\"eou_metrics_collected\", eou_metrics_wrapper)\n",
    "\n",
    "        def tts_metrics_wrapper(metrics: TTSMetrics):\n",
    "            asyncio.create_task(self.on_tts_metrics_collected(metrics))\n",
    "        tts.on(\"metrics_collected\", tts_metrics_wrapper)\n",
    "\n",
    "    async def on_llm_metrics_collected(self, metrics: LLMMetrics) -> None:\n",
    "        \"\"\"Process and display LLM performance metrics.\"\"\"\n",
    "        print(\"\\n=== LLM Performance Metrics ===\")\n",
    "        print(f\"Prompt Tokens: {metrics.prompt_tokens}\")\n",
    "        print(f\"Completion Tokens: {metrics.completion_tokens}\")\n",
    "        print(f\"Processing Speed: {metrics.tokens_per_second:.2f} tokens/sec\")\n",
    "        print(f\"Time to First Token: {metrics.ttft:.3f}s\")\n",
    "        print(\"============================\\n\")\n",
    "\n",
    "    async def on_stt_metrics_collected(self, metrics: STTMetrics) -> None:\n",
    "        \"\"\"Process and display Speech-to-Text metrics.\"\"\"\n",
    "        print(\"\\n=== STT Performance Metrics ====\")\n",
    "        print(f\"Processing Time: {metrics.duration:.3f}s\")\n",
    "        print(f\"Audio Length: {metrics.audio_duration:.3f}s\")\n",
    "        print(f\"Streaming: {'Enabled' if metrics.streamed else 'Disabled'}\")\n",
    "        print(\"==============================\\n\")\n",
    "\n",
    "    async def on_eou_metrics_collected(self, metrics: EOUMetrics) -> None:\n",
    "        \"\"\"Process and display End-of-Utterance detection metrics.\"\"\"\n",
    "        print(\"\\n=== Utterance Detection Metrics ====\")\n",
    "        print(f\"Detection Delay: {metrics.end_of_utterance_delay:.3f}s\")\n",
    "        print(f\"Transcription Delay: {metrics.transcription_delay:.3f}s\")\n",
    "        print(\"=================================\\n\")\n",
    "\n",
    "    async def on_tts_metrics_collected(self, metrics: TTSMetrics) -> None:\n",
    "        \"\"\"Process and display Text-to-Speech metrics.\"\"\"\n",
    "        print(\"\\n=== TTS Performance Metrics ====\")\n",
    "        print(f\"Time to First Byte: {metrics.ttfb:.3f}s\")\n",
    "        print(f\"Generation Time: {metrics.duration:.3f}s\")\n",
    "        print(f\"Audio Duration: {metrics.audio_duration:.3f}s\")\n",
    "        print(f\"Streaming: {'Enabled' if metrics.streamed else 'Disabled'}\")\n",
    "        print(\"==============================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e3528e-d363-442c-96b1-fc146327341d",
   "metadata": {},
   "source": [
    "- To speak to the agent, unmute the microphone symbol on the left. You can ignore the 'Start Audio' button.\n",
    "- The agent will try to detect the language you are speaking. To help it, start by speaking a long phrase like \"hello, how are you today\" in the language of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbcacb-b143-46d5-a649-27c0eb3b5cf6",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "jupyter.run_app(WorkerOptions(entrypoint_fnc=entrypoint), jupyter_url=\"https://jupyter-api-livekit.vercel.app/api/join-token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3fb812-e7f8-4a5b-9923-ed5686b3884d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ae558-f8da-43f3-b1f5-2b6e2f163ff9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
